{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "import nltk\n",
    "import preprocessor as p\n",
    "import joblib\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = [\"art2.csv\", \"game2.csv\", \"movie2.csv\",\"music2.csv\",\"politic2.csv\",\"science2.csv\",\"sport2.csv\",\"technology2.csv\",\"travel2.csv\",\"TV2.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in data_array:\n",
    "    data.append(pd.read_csv(i))\n",
    "df = pd.concat(data)\n",
    "#df.drop([\"index\"], inplace=True)\n",
    "df = df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Today's #DailyDeviation winners are here! Ft: ...</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Check out today's #DailyDeviation winners! Ft:...</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANNOUNCEMENT! My very first @Kickstarter! **Si...</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Geometric Pattern: Intersect Square: Black/Bat...</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Geometric Pattern: Intersect Square: Black/Bat...</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0    1\n",
       "0  Today's #DailyDeviation winners are here! Ft: ...  art\n",
       "1  Check out today's #DailyDeviation winners! Ft:...  art\n",
       "2  ANNOUNCEMENT! My very first @Kickstarter! **Si...  art\n",
       "3  Geometric Pattern: Intersect Square: Black/Bat...  art\n",
       "4  Geometric Pattern: Intersect Square: Black/Bat...  art"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'0': \"tweet_text\", '1' : \"category\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new columns for all hashtags\n",
    "df['hashtags'] = df['tweet_text'].apply(lambda x: re.findall(r\"#(\\w+)\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>category</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Today's #DailyDeviation winners are here! Ft: ...</td>\n",
       "      <td>art</td>\n",
       "      <td>[DailyDeviation, Art]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Check out today's #DailyDeviation winners! Ft:...</td>\n",
       "      <td>art</td>\n",
       "      <td>[DailyDeviation, Art]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANNOUNCEMENT! My very first @Kickstarter! **Si...</td>\n",
       "      <td>art</td>\n",
       "      <td>[warlock, BATTLEOFTHEBARDS, dnd, bards, art, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Geometric Pattern: Intersect Square: Black/Bat...</td>\n",
       "      <td>art</td>\n",
       "      <td>[art, geometricpattern, geometry, retro, circl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Geometric Pattern: Intersect Square: Black/Bat...</td>\n",
       "      <td>art</td>\n",
       "      <td>[art, geometricpattern, geometry, retro, circl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text category  \\\n",
       "0  Today's #DailyDeviation winners are here! Ft: ...      art   \n",
       "1  Check out today's #DailyDeviation winners! Ft:...      art   \n",
       "2  ANNOUNCEMENT! My very first @Kickstarter! **Si...      art   \n",
       "3  Geometric Pattern: Intersect Square: Black/Bat...      art   \n",
       "4  Geometric Pattern: Intersect Square: Black/Bat...      art   \n",
       "\n",
       "                                            hashtags  \n",
       "0                              [DailyDeviation, Art]  \n",
       "1                              [DailyDeviation, Art]  \n",
       "2  [warlock, BATTLEOFTHEBARDS, dnd, bards, art, s...  \n",
       "3  [art, geometricpattern, geometry, retro, circl...  \n",
       "4  [art, geometricpattern, geometry, retro, circl...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove just hashtag tag then using tweet-preprocessor for links, emoticons, etc. then remove punctuations\n",
    "for i in range(len(df[\"tweet_text\"])):\n",
    "    #df[\"tweet_text\"][i] = re.sub(r'(?is)#', '', df[\"tweet_text\"][i])\n",
    "    df[\"tweet_text\"][i] = p.clean(df[\"tweet_text\"][i])\n",
    "    df[\"tweet_text\"][i] = re.sub(r'[^\\w\\s]','',df[\"tweet_text\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Check out todays winners Ft    and many moreCheck out all of the winning here'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"tweet_text\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization and stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update(('new','year', 'happy', 'first', 'one', 'lets', 'best', 'via', 'two', 'three', 'amp'))\n",
    "for i in range(len(df[\"tweet_text\"])):\n",
    "    word_tokens = word_tokenize(df[\"tweet_text\"][i].lower())\n",
    "    filtered_sentence = \"\"\n",
    "    for w in word_tokens: \n",
    "        if w not in stop_words: \n",
    "            filtered_sentence += w\n",
    "            filtered_sentence += \" \"\n",
    "    filtered_sentence = filtered_sentence.strip()\n",
    "    df[\"tweet_text\"][i] = filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer \n",
    "for i in range(len(df[\"tweet_text\"])):\n",
    "    sentence = \"\"\n",
    "    tweet = df[\"tweet_text\"][i].lower().split()\n",
    "    porter = nltk.SnowballStemmer('english')\n",
    "    WNlemma = WordNetLemmatizer()\n",
    "    for k in tweet:\n",
    "        stemming = porter.stem(k)\n",
    "        lem = WNlemma.lemmatize(stemming)\n",
    "        sentence += lem\n",
    "        sentence += \" \"\n",
    "    sentence = sentence.strip()\n",
    "    df[\"tweet_text\"][i] = sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = df[\"category\"].unique().tolist()\n",
    "for i in categories:\n",
    "    df2[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-0da9a966b4fe>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2[cat][i] = 1\n"
     ]
    }
   ],
   "source": [
    "for cat in categories:\n",
    "    for i in range(len(df2[cat])):\n",
    "        if df2[\"category\"][i]  == cat:\n",
    "            df2[cat][i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>category</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>art</th>\n",
       "      <th>game</th>\n",
       "      <th>movie</th>\n",
       "      <th>music</th>\n",
       "      <th>politic</th>\n",
       "      <th>science</th>\n",
       "      <th>sport</th>\n",
       "      <th>technology</th>\n",
       "      <th>travel</th>\n",
       "      <th>TV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>today winner ft mani morecheck win</td>\n",
       "      <td>art</td>\n",
       "      <td>[DailyDeviation, Art]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>check today winner ft mani morecheck win</td>\n",
       "      <td>art</td>\n",
       "      <td>[DailyDeviation, Art]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>announc siren song battl bard live april partn...</td>\n",
       "      <td>art</td>\n",
       "      <td>[warlock, BATTLEOFTHEBARDS, dnd, bards, art, s...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>geometr pattern intersect squar blackbattleshi...</td>\n",
       "      <td>art</td>\n",
       "      <td>[art, geometricpattern, geometry, retro, circl...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>geometr pattern intersect squar blackbattleshi...</td>\n",
       "      <td>art</td>\n",
       "      <td>[art, geometricpattern, geometry, retro, circl...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text category  \\\n",
       "0                 today winner ft mani morecheck win      art   \n",
       "1           check today winner ft mani morecheck win      art   \n",
       "2  announc siren song battl bard live april partn...      art   \n",
       "3  geometr pattern intersect squar blackbattleshi...      art   \n",
       "4  geometr pattern intersect squar blackbattleshi...      art   \n",
       "\n",
       "                                            hashtags  art  game  movie  music  \\\n",
       "0                              [DailyDeviation, Art]    1     0      0      0   \n",
       "1                              [DailyDeviation, Art]    1     0      0      0   \n",
       "2  [warlock, BATTLEOFTHEBARDS, dnd, bards, art, s...    1     0      0      0   \n",
       "3  [art, geometricpattern, geometry, retro, circl...    1     0      0      0   \n",
       "4  [art, geometricpattern, geometry, retro, circl...    1     0      0      0   \n",
       "\n",
       "   politic  science  sport  technology  travel  TV  \n",
       "0        0        0      0           0       0   0  \n",
       "1        0        0      0           0       0   0  \n",
       "2        0        0      0           0       0   0  \n",
       "3        0        0      0           0       0   0  \n",
       "4        0        0      0           0       0   0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "from nltk import word_tokenize\n",
    "\n",
    "fdist = FreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "art:  art 270 amaz 237 commiss 106 day 104 help 96 love 95 piper 93 time 92 go 91 draw 91 \n",
      "\n",
      "game:  play 490 game 428 year 290 day 273 special 246 everi 223 prepar 211 gift 209 obey 207 yearthank 206 \n",
      "\n",
      "movie:  movi 438 watch 202 film 191 alan 114 review 114 full 111 last 107 found 99 footag 91 vintag 90 \n",
      "\n",
      "music:  music 318 song 177 play 170 live 146 check 134 video 117 love 106 tune 105 listen 101 come 92 \n",
      "\n",
      "politic:  presid 234 trump 216 vote 216 elect 144 senat 126 stimulus 108 bill 108 u 108 veto 108 calif 108 \n",
      "\n",
      "science:  u 370 follow 218 scienc 216 learn 200 day 147 creat 136 get 121 would 121 machin 119 az 117 \n",
      "\n",
      "sport:  sport 207 anoth 159 post 150 favorit 147 insta 145 make 127 thank 125 support 120 live 119 sign 110 \n",
      "\n",
      "technology:  use 117 day 111 project 101 free 86 javascript 82 technolog 80 code 79 intellig 78 ai 77 get 76 \n",
      "\n",
      "travel:  travel 293 u 147 check 101 experi 100 visit 96 stay 96 amaz 94 beauti 94 slide 92 thing 92 \n",
      "\n",
      "TV:  tv 356 along 192 see 184 watch 164 much 153 show 150 come 138 fun 120 televis 106 get 106 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in categories: \n",
    "    freq = FreqDist(sum(df2[df2[\"category\"]== i].tweet_text.map(word_tokenize), []))\n",
    "    sort_orders = sorted(freq.items(), key=lambda x: x[1], reverse=True)\n",
    "    count = 0\n",
    "    print(i + \": \", end= \" \")\n",
    "    for k in sort_orders:\n",
    "        print(k[0], k[1], end= \" \")\n",
    "        count += 1\n",
    "        if count == 10:\n",
    "            break\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X = df2[\"tweet_text\"]\n",
    "#y = df2.drop(columns = [\"tweet_text\", \"category\", \"hashtags\"])\n",
    "\n",
    "train, test = train_test_split(df2, random_state=42, test_size=0.2)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train['tweet_text']\n",
    "test_text = test['tweet_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"preprocessed_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(ngram_range=(1, 2), strip_accents='unicode')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#vectorizer = CountVectorizer(strip_accents='unicode', analyzer='word', ngram_range=(1,2))\n",
    "vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', ngram_range=(1,2), norm='l2')\n",
    "vectorizer.fit(train_text)\n",
    "vectorizer.fit(test_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorizer.transform(train_text)\n",
    "y_train = train.drop(columns = [\"tweet_text\", \"category\", \"hashtags\"])\n",
    "\n",
    "x_test = vectorizer.transform(test_text)\n",
    "y_test = test.drop(columns = [\"tweet_text\", \"category\", \"hashtags\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Label ClassificationMulti-Label Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Processing art comments...**\n",
      "Test accuracy is 0.9343454258675079\n",
      "\n",
      "\n",
      "**Processing game comments...**\n",
      "Test accuracy is 0.9337539432176656\n",
      "\n",
      "\n",
      "**Processing movie comments...**\n",
      "Test accuracy is 0.9380914826498423\n",
      "\n",
      "\n",
      "**Processing music comments...**\n",
      "Test accuracy is 0.9152208201892744\n",
      "\n",
      "\n",
      "**Processing politic comments...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing science comments...**\n",
      "Test accuracy is 0.9361198738170347\n",
      "\n",
      "\n",
      "**Processing sport comments...**\n",
      "Test accuracy is 0.936711356466877\n",
      "\n",
      "\n",
      "**Processing technology comments...**\n",
      "Test accuracy is 0.9378943217665615\n",
      "\n",
      "\n",
      "**Processing travel comments...**\n",
      "Test accuracy is 0.9240930599369085\n",
      "\n",
      "\n",
      "**Processing TV comments...**\n",
      "Test accuracy is 0.9589905362776026\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LogReg_pipeline = Pipeline([\n",
    "                ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=-1)),\n",
    "            ])\n",
    "\n",
    "for category in categories:\n",
    "    print('**Processing {} comments...**'.format(category))\n",
    "    \n",
    "    # Training logistic regression model on train data\n",
    "    LogReg_pipeline.fit(x_train, train[category])\n",
    "    \n",
    "    # calculating test accuracy\n",
    "    prediction = LogReg_pipeline.predict(x_test)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(test[category], prediction)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Processing art comments...**\n",
      "Test accuracy is 0.9349369085173501\n",
      "\n",
      "\n",
      "**Processing game comments...**\n",
      "Test accuracy is 0.9481466876971609\n",
      "\n",
      "\n",
      "**Processing movie comments...**\n",
      "Test accuracy is 0.9430205047318612\n",
      "\n",
      "\n",
      "**Processing music comments...**\n",
      "Test accuracy is 0.9305993690851735\n",
      "\n",
      "\n",
      "**Processing politic comments...**\n",
      "Test accuracy is 0.9970425867507886\n",
      "\n",
      "\n",
      "**Processing science comments...**\n",
      "Test accuracy is 0.951301261829653\n",
      "\n",
      "\n",
      "**Processing sport comments...**\n",
      "Test accuracy is 0.95051261829653\n",
      "\n",
      "\n",
      "**Processing technology comments...**\n",
      "Test accuracy is 0.9536671924290221\n",
      "\n",
      "\n",
      "**Processing travel comments...**\n",
      "Test accuracy is 0.9376971608832808\n",
      "\n",
      "\n",
      "**Processing TV comments...**\n",
      "Test accuracy is 0.9700315457413249\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LogReg_pipeline = Pipeline([\n",
    "                ('clf', OneVsRestClassifier(MultinomialNB(fit_prior=True, class_prior=None), n_jobs=-1)),\n",
    "            ])\n",
    "\n",
    "for category in categories:\n",
    "    print('**Processing {} comments...**'.format(category))\n",
    "    \n",
    "    # Training logistic regression model on train data\n",
    "    LogReg_pipeline.fit(x_train, train[category])\n",
    "    \n",
    "    # calculating test accuracy\n",
    "    prediction = LogReg_pipeline.predict(x_test)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(test[category], prediction)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Processing art comments...**\n",
      "Test accuracy is 0.9656940063091483\n",
      "\n",
      "\n",
      "**Processing game comments...**\n",
      "Test accuracy is 0.9725946372239748\n",
      "\n",
      "\n",
      "**Processing movie comments...**\n",
      "Test accuracy is 0.9712145110410094\n",
      "\n",
      "\n",
      "**Processing music comments...**\n",
      "Test accuracy is 0.9524842271293376\n",
      "\n",
      "\n",
      "**Processing politic comments...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing science comments...**\n",
      "Test accuracy is 0.9674684542586751\n",
      "\n",
      "\n",
      "**Processing sport comments...**\n",
      "Test accuracy is 0.9704258675078864\n",
      "\n",
      "\n",
      "**Processing technology comments...**\n",
      "Test accuracy is 0.9800867507886435\n",
      "\n",
      "\n",
      "**Processing travel comments...**\n",
      "Test accuracy is 0.9572160883280757\n",
      "\n",
      "\n",
      "**Processing TV comments...**\n",
      "Test accuracy is 0.9982255520504731\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LogReg_pipeline = Pipeline([\n",
    "                ('clf', OneVsRestClassifier(CalibratedClassifierCV(LinearSVC()), n_jobs=-1)),\n",
    "            ])\n",
    "\n",
    "for category in categories:\n",
    "    print('**Processing {} comments...**'.format(category))\n",
    "    \n",
    "    # Training logistic regression model on train data\n",
    "    LogReg_pipeline.fit(x_train, train[category])\n",
    "    \n",
    "    # calculating test accuracy\n",
    "    prediction = LogReg_pipeline.predict(x_test)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(test[category], prediction)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(vectorizer, open(\"vector.pickel\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogReg_pipeline = Pipeline([\n",
    "                ('clf', OneVsRestClassifier(MultinomialNB(fit_prior=True, class_prior=None), n_jobs=-1)),\n",
    "            ])\n",
    "with open(\"models2.pckl\", \"wb\") as f:\n",
    "    for category in categories:\n",
    "        LogReg_pipeline.fit(x_train, train[category])\n",
    "        pickle.dump(LogReg_pipeline, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
